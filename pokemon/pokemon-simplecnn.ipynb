{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/pokemon_train.npy\n",
      "../input/pokemon_test.npy\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"../input/pokemon_train.npy\"\n",
    "TEST_PATH = \"../input/pokemon_test.npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    train_data = np.load(TRAIN_PATH)\n",
    "    test_data = np.load(TEST_PATH)\n",
    "\n",
    "    # random\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    indices = np.arange(len(train_data))\n",
    "    rng.shuffle(indices)\n",
    "    train_data = train_data[indices]\n",
    "\n",
    "    val_data = train_data[:100]\n",
    "\n",
    "    train_data = train_data[100:]\n",
    "\n",
    "    x_train = train_data[:,1:]\n",
    "    y_train = train_data[:,0]\n",
    "\n",
    "    x_val = val_data[:,1:]\n",
    "    y_val = val_data[:,0]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 2,603,205\n",
      "Trainable params: 2,603,205\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 44s 443ms/step - loss: 1.0523 - acc: 0.5685 - val_loss: 0.7347 - val_acc: 0.7300\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 43s 429ms/step - loss: 0.5650 - acc: 0.7990 - val_loss: 0.6741 - val_acc: 0.7500\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 43s 428ms/step - loss: 0.4510 - acc: 0.8400 - val_loss: 0.5441 - val_acc: 0.7600\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 44s 436ms/step - loss: 0.3591 - acc: 0.8820 - val_loss: 0.3758 - val_acc: 0.8700\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 43s 428ms/step - loss: 0.3222 - acc: 0.8890 - val_loss: 0.5278 - val_acc: 0.8300\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 43s 428ms/step - loss: 0.2619 - acc: 0.9080 - val_loss: 0.3982 - val_acc: 0.8300\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 43s 426ms/step - loss: 0.2472 - acc: 0.9140 - val_loss: 0.3743 - val_acc: 0.8900\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 43s 430ms/step - loss: 0.2033 - acc: 0.9340 - val_loss: 0.3418 - val_acc: 0.9300\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 43s 426ms/step - loss: 0.1878 - acc: 0.9445 - val_loss: 0.3753 - val_acc: 0.9100\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 42s 424ms/step - loss: 0.1699 - acc: 0.9500 - val_loss: 0.3279 - val_acc: 0.9300\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 42s 422ms/step - loss: 0.1568 - acc: 0.9530 - val_loss: 0.3824 - val_acc: 0.9300\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 42s 423ms/step - loss: 0.1418 - acc: 0.9545 - val_loss: 0.5002 - val_acc: 0.8400\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 43s 426ms/step - loss: 0.1138 - acc: 0.9650 - val_loss: 0.4302 - val_acc: 0.8900\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 42s 424ms/step - loss: 0.1148 - acc: 0.9605 - val_loss: 0.3567 - val_acc: 0.9200\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 43s 434ms/step - loss: 0.0998 - acc: 0.9600 - val_loss: 0.3725 - val_acc: 0.9000\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 43s 429ms/step - loss: 0.0968 - acc: 0.9685 - val_loss: 0.3782 - val_acc: 0.9100\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 43s 427ms/step - loss: 0.0862 - acc: 0.9715 - val_loss: 0.3556 - val_acc: 0.9300\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 42s 423ms/step - loss: 0.0898 - acc: 0.9685 - val_loss: 0.4038 - val_acc: 0.9000\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 42s 423ms/step - loss: 0.0797 - acc: 0.9720 - val_loss: 0.3848 - val_acc: 0.9100\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 42s 422ms/step - loss: 0.0593 - acc: 0.9750 - val_loss: 0.5397 - val_acc: 0.8800\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 42s 423ms/step - loss: 0.0718 - acc: 0.9740 - val_loss: 0.5430 - val_acc: 0.8600\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 43s 429ms/step - loss: 0.0831 - acc: 0.9680 - val_loss: 0.4037 - val_acc: 0.9100\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 43s 425ms/step - loss: 0.0578 - acc: 0.9795 - val_loss: 0.4346 - val_acc: 0.9100\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 43s 426ms/step - loss: 0.0735 - acc: 0.9750 - val_loss: 0.6171 - val_acc: 0.8700\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 43s 425ms/step - loss: 0.0553 - acc: 0.9800 - val_loss: 0.5258 - val_acc: 0.8700\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 42s 421ms/step - loss: 0.0683 - acc: 0.9765 - val_loss: 0.3064 - val_acc: 0.9400\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 42s 424ms/step - loss: 0.0610 - acc: 0.9790 - val_loss: 0.3929 - val_acc: 0.9000\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 42s 422ms/step - loss: 0.0574 - acc: 0.9795 - val_loss: 0.4149 - val_acc: 0.9100\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 43s 429ms/step - loss: 0.0539 - acc: 0.9805 - val_loss: 0.3607 - val_acc: 0.9100\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 43s 425ms/step - loss: 0.0463 - acc: 0.9845 - val_loss: 0.6004 - val_acc: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f64b18a6438>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 113\n",
    "model = build_model()\n",
    "x_train, y_train, x_val, y_val, x_test = preprocess_data()\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], 128,128,3))\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], 128,128,3))\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "validation_datagen.fit(x_val)\n",
    "\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size=20),\n",
    "                  steps_per_epoch=100, \n",
    "                  epochs=30,\n",
    "                  validation_data=validation_datagen.flow(x_val, y_val, batch_size=20),\n",
    "                  validation_steps=20)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 3 3 4 1 3 2 2 1 0 0 2 2 2 3 2 1 0 1 4 4 2 4 3 0 3 0 4 1 1 1 1 3 2 0\n",
      " 3 3 1 1 4 2 2 1 1 4 3 2 1 1 3 0 3 0 4 4 3 2 1 0 1 3 0 0 2 4 2 3 0 1 0 3 4\n",
      " 2 0 3 2 2 1 1 3 1 2 1 2 3 3 4 3 2 2 0 1 2 2 0 3 4 3 1 4 2 3 2 3 4 2 1 4 0\n",
      " 1 0 0 2 2 3 1 3 2 3 2 1 3 0 2 3 2 1 2 4 4 0 0 0 0 1 3 1 0 2 1 1 4 1 2 0 2\n",
      " 3 1 3 3 1 3 1 0 1 4 2 0 4 2 1 0 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "x_test = x_test.reshape(-1, 128, 128, 3)\n",
    "x_test = x_test / 255\n",
    "predict_labels = model.predict_classes(x_test, batch_size=32)\n",
    "print(predict_labels)\n",
    "predict_label_csv = np.hstack([(np.arange(predict_labels.shape[0])+1).reshape([-1, 1]), predict_labels.reshape([-1, 1])])\n",
    "np.savetxt('predict_label.csv', predict_label_csv, delimiter = ',', header='Id,Category')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
